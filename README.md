# **LawSage.AI**  
**Empowering Legal Professionals with AI-Driven Insights**

![LawSage.AI Banner](frontend/static/assets/banner.png)
 

LawSage.AI is an end-to-end AI-powered legal assistance platform designed to automate legal document understanding, summarization, simplification, and legal research chat using modern Large Language Models (LLMs).

The system is built with performance, modularity, and deployment readiness in mind and supports multiple fast-response LLMs, dynamic model routing, and cloud-scale deployment.



ğŸš€ Key Capabilities


ğŸ“„ Legal Document Upload & Processing

	Supports PDF-based legal documents

	Handles both text-based and scanned documents (OCR fallback)



ğŸ§  AI-Driven Legal Summarization

	Concise summaries of long legal documents

	Uses domain-tuned legal summarization models



ğŸ—£ Legal Language Simplification

	Converts complex legal jargon into understandable language

	Ideal for non-lawyers and first-time readers



âš¡ Fast Legal Research Chat

	Multi-model architecture for rapid responses

	Optimized for latency and scalability



â˜ Production-Grade Deployment

	Fully deployed on a cloud VM for 24Ã—7 availability

	Ready for containerization and CI/CD



ğŸ§  Model Architecture & Evolution


âš ï¸ Important Note on Model Usage

The project initially experimented with Microsoft Phi models

These were later completely deprecated

Replaced with faster, more efficient, and more scalable LLMs



âœ… Current Model Strategy

âš¡ Tiny & Distilled Models for ultra-fast responses

ğŸ§  LLaMA-based & Mistral-based models for reasoning-heavy tasks



ğŸ” Dynamic Model Routing based on:

	Query complexity

	Response latency

	Token constraints


![LawSage.AI ss1](frontend/static/assets/ss1.png)



![LawSage.AI ss1](frontend/static/assets/ss2.png)



![LawSage.AI ss1](frontend/static/assets/ss3.png)




This architecture significantly improves speed, reliability, and production usability compared to the earlier Phi-based approach.


## ğŸ— High-Level System Architecture

```text
User
â”‚
â–¼ Frontend (HTML / CSS / JS)
â”‚
â–¼ Flask API Gateway
â”‚
â”œâ”€â”€ Document Processing Service
â”‚   â”œâ”€â”€ PDF Parsing + OCR
â”‚
â”œâ”€â”€ Summarization Service
â”‚   â””â”€â”€ Legal Pegasus
â”‚
â”œâ”€â”€ Simplification Service
â”‚   â””â”€â”€ LegalBERT-BART
â”‚
â”œâ”€â”€ Fast Chat Router
â”‚   â”œâ”€â”€ Tiny LLMs (Low latency)
â”‚   â””â”€â”€ LLaMA / Mistral Models
â”‚
â””â”€â”€ Database
    â””â”€â”€ Chat History, Metadata
```


##ğŸ§© Project Structure

```text
LawSage.AI/
â”œâ”€â”€ backend/
â”‚ â”œâ”€â”€ app.py
â”‚ â”œâ”€â”€ models/
â”‚ â”‚ â”œâ”€â”€ fast_chat_model.py
â”‚ â”‚ â”œâ”€â”€ summarizer_model.ipynb
â”‚ â”‚ â””â”€â”€ legal_research_model.py
â”‚ â”œâ”€â”€ services/
â”‚ â”‚ â”œâ”€â”€ document_processing/
â”‚ â”‚ â”œâ”€â”€ summarization/
â”‚ â”‚ â”œâ”€â”€ simplification/
â”‚ â”‚ â””â”€â”€ research_assistant/
â”‚ â”œâ”€â”€ migrations/
â”‚ â””â”€â”€ utils/
â”‚
â”œâ”€â”€ frontend/
â”‚ â”œâ”€â”€ templates/
â”‚ â””â”€â”€ static/
â”‚
â”œâ”€â”€ tests/
â”œâ”€â”€ uploads/
â”œâ”€â”€ instance/
â”œâ”€â”€ sqlscript.sql
â””â”€â”€ README.md
```

âš™ï¸ Tech Stack


Backend

Python

Flask

SQLAlchemy

PyTorch / Transformers




AI & NLP


HuggingFace Transformers

Legal-Pegasus

LegalBERT-BART

LLaMA-based models

Distilled fast-response chat models




Document Processing


pdfplumber

PyPDF2

pytesseract (OCR)

Pillow (PIL)




Infrastructure


Cloud Virtual Machine

Environment-based configuration

Deployment-ready architecture




â˜ï¸ Cloud Deployment (24Ã—7)



LawSage.AI is fully deployed on a dedicated Virtual Machine using Microsoft Azure specifically on -


http://4.187.225.163:5000


enabling:

âœ… Always-on availability

âœ… Public IP access

âœ… Production-grade reliability

âœ… Future scalability (Docker / Kubernetes ready)


The VM handles:

Backend API

Model inference

Document processing

Database connectivity


This allows LawSage.AI to function as a real production system, not just a local demo.




ğŸ› ï¸ Local Setup (Quick Start)

```
git clone https://github.com/Codeatlight/LawSage.AI
cd LawSage.AI
python -m venv venv
source venv/bin/activate
pip install -r backend/requirements.txt
python backend/app.py
```


Open:
http://localhost:5000

